{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b595da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Text\n",
    "\n",
    "from absl import logging\n",
    "from tfx.orchestration import metadata, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa50240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PIPELINE_NAME = \"pilcotech-obesity-pipeline\"\n",
    "\n",
    "# pipeline inputs\n",
    "DATA_ROOT = \"data\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
    "# requirement_file = os.path.join(root, \"requirements.txt\")\n",
    "\n",
    "# pipeline outputs\n",
    "OUTPUT_BASE = \"output\"\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f92b4",
   "metadata": {},
   "source": [
    "Inisisasi Tfx pipeline komponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67fb14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import (\n",
    "    CsvExampleGen,\n",
    "    StatisticsGen,\n",
    "    SchemaGen,\n",
    "    ExampleValidator,\n",
    "    Tuner,\n",
    "    Transform,\n",
    "    Trainer,\n",
    "    Evaluator,\n",
    "    Pusher,\n",
    ")\n",
    "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
    "    LatestBlessedModelStrategy,\n",
    ")\n",
    "\n",
    "\n",
    "def init_components(\n",
    "    data_dir,\n",
    "    transform_module,\n",
    "    training_module,\n",
    "    tuner_module,\n",
    "    training_steps,\n",
    "    eval_steps,\n",
    "    serving_model_dir,\n",
    "):\n",
    "    \"\"\"Initiate tfx pipeline components\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): a path to the data\n",
    "        transform_module (str): a path to the transform_module\n",
    "        training_module (str): a path to the transform_module\n",
    "        training_steps (int): number of training steps\n",
    "        eval_steps (int): number of eval steps\n",
    "        serving_model_dir (str): a path to the serving model directory\n",
    "\n",
    "    Returns:\n",
    "        TFX components\n",
    "    \"\"\"\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config=example_gen_pb2.SplitConfig(\n",
    "            splits=[\n",
    "                example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=8),\n",
    "                example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=2),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    example_gen = CsvExampleGen(input_base=data_dir, output_config=output)\n",
    "\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n",
    "\n",
    "    schema_gen = SchemaGen(statistics=statistics_gen.outputs[\"statistics\"])\n",
    "\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "    )\n",
    "\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        module_file=os.path.abspath(transform_module),\n",
    "    )\n",
    "\n",
    "    tuner = Tuner(\n",
    "        module_file=os.path.abspath(tuner_module),\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        transform_graph=transform.outputs[\"transform_graph\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        train_args=trainer_pb2.TrainArgs(splits=[\"train\"], num_steps=training_steps),\n",
    "        eval_args=trainer_pb2.EvalArgs(splits=[\"eval\"], num_steps=eval_steps),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        module_file=os.path.abspath(training_module),\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        transform_graph=transform.outputs[\"transform_graph\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        hyperparameters=tuner.outputs[\"best_hyperparameters\"],\n",
    "        train_args=trainer_pb2.TrainArgs(splits=[\"train\"], num_steps=training_steps),\n",
    "        eval_args=trainer_pb2.EvalArgs(splits=[\"eval\"], num_steps=eval_steps),\n",
    "    )\n",
    "\n",
    "    model_resolver = Resolver(\n",
    "        strategy_class=LatestBlessedModelStrategy,\n",
    "        model=Channel(type=Model),\n",
    "        model_blessing=Channel(type=ModelBlessing),\n",
    "    ).with_id(\"Latest_blessed_model_resolver\")\n",
    "\n",
    "    slicing_specs = [\n",
    "        tfma.SlicingSpec(),\n",
    "        tfma.SlicingSpec(feature_keys=[\"Gender_xf\"]),\n",
    "    ]\n",
    "\n",
    "    metrics_specs = [\n",
    "        tfma.MetricsSpec(\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name=\"AUC\"),\n",
    "                tfma.MetricConfig(class_name=\"Precision\"),\n",
    "                tfma.MetricConfig(class_name=\"Recall\"),\n",
    "                tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                tfma.MetricConfig(\n",
    "                    class_name=\"SparseCategoricalAccuracy\",\n",
    "                    threshold=tfma.MetricThreshold(\n",
    "                        value_threshold=tfma.GenericValueThreshold(\n",
    "                            lower_bound={\"value\": 0.5}\n",
    "                        ),\n",
    "                        change_threshold=tfma.GenericChangeThreshold(\n",
    "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                            absolute={\"value\": 0.0001},\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=\"Label_xf\")],\n",
    "        slicing_specs=slicing_specs,\n",
    "        metrics_specs=metrics_specs,\n",
    "    )\n",
    "\n",
    "    evaluator = Evaluator(\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        baseline_model=model_resolver.outputs[\"model\"],\n",
    "        eval_config=eval_config,\n",
    "    )\n",
    "\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        model_blessing=evaluator.outputs[\"blessing\"],\n",
    "        push_destination=pusher_pb2.PushDestination(\n",
    "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "                base_directory=serving_model_dir\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    components = (\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        tuner,\n",
    "        trainer,\n",
    "        model_resolver,\n",
    "        evaluator,\n",
    "        pusher,\n",
    "    )\n",
    "\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f09be8",
   "metadata": {},
   "source": [
    "membuat module transform file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e7cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/transform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRANSFORM_MODULE_FILE}\n",
    "\n",
    "\"\"\"Transform module\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "CATEGORICAL_FEATURES = {\n",
    "    \"Gender\": 2,\n",
    "}\n",
    "NUMERICAL_FEATURES = [\"Height\", \"Weight\", \"BMI\", \"Age\"]\n",
    "LABEL_KEY = \"Label\"\n",
    "\n",
    "\n",
    "def transformed_name(key):\n",
    "    \"\"\"Renaming transformed features\"\"\"\n",
    "    return key + \"_xf\"\n",
    "\n",
    "\n",
    "def convert_num_to_one_hot(label_tensor, num_labels=2):\n",
    "    \"\"\"\n",
    "    Convert a label (0 or 1) into a one-hot vector\n",
    "    Args:\n",
    "        int: label_tensor (0 or 1)\n",
    "    Returns\n",
    "        label tensor\n",
    "    \"\"\"\n",
    "    one_hot_tensor = tf.one_hot(label_tensor, num_labels)\n",
    "    return tf.reshape(one_hot_tensor, [-1, num_labels])\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"\n",
    "    Preprocess input features into transformed features\n",
    "\n",
    "    Args:\n",
    "        inputs: map from feature keys to raw features.\n",
    "\n",
    "    Return:\n",
    "        outputs: map from feature keys to transformed features.\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = {}\n",
    "\n",
    "    # KATEGORIKAL\n",
    "    for key in CATEGORICAL_FEATURES:\n",
    "        dim = CATEGORICAL_FEATURES[key]\n",
    "        int_value = tft.compute_and_apply_vocabulary(inputs[key], top_k=dim + 1)\n",
    "        outputs[transformed_name(key)] = convert_num_to_one_hot(\n",
    "            int_value, num_labels=dim + 1\n",
    "        )\n",
    "\n",
    "    # NUMERIKAL\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        outputs[transformed_name(feature)] = tf.expand_dims(\n",
    "            tft.scale_to_0_1(inputs[feature]), -1\n",
    "        )\n",
    "\n",
    "    # LABEL\n",
    "    outputs[transformed_name(LABEL_KEY)] = tft.compute_and_apply_vocabulary(\n",
    "        inputs[LABEL_KEY], 4\n",
    "    )\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f07701",
   "metadata": {},
   "source": [
    "membuat module tuner file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ab538d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/tuner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TUNER_MODULE_FILE}\n",
    "# Import library\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from tfx.components.tuner.component import TunerFnResult\n",
    "\n",
    "from transform import CATEGORICAL_FEATURES, NUMERICAL_FEATURES, transformed_name\n",
    "from trainer import input_fn\n",
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    This function defines a Keras model and returns the model as a Keras object.\n",
    "    \"\"\"\n",
    "\n",
    "    input_features = []\n",
    "\n",
    "    for key in CATEGORICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(CATEGORICAL_FEATURES[key] + 1,), name=transformed_name(key))\n",
    "        )\n",
    "\n",
    "    for key in NUMERICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1,), name=transformed_name(key))\n",
    "        )\n",
    "\n",
    "    concat = tf.keras.layers.concatenate(input_features)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        hp.Choice('units_1', [128, 256, 512]),\n",
    "        activation='relu'\n",
    "    )(concat)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('dropout_1', [0.2, 0.3, 0.4]))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        hp.Choice('units_2', [64, 128]),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('dropout_2', [0.2, 0.3, 0.4]))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        hp.Choice('units_3', [32, 64]),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('dropout_3', [0.2, 0.3, 0.4]))(x)\n",
    "\n",
    "    num_classes = 4  # Ganti jika jumlah kelas berbeda\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def tuner_fn(fn_args: FnArgs):\n",
    "    \"\"\"\n",
    "    Build the tuner and return TunerFnResult to TFX.\n",
    "    \"\"\"\n",
    "\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    train_dataset = input_fn(\n",
    "        fn_args.train_files,\n",
    "        tf_transform_output,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    eval_dataset = input_fn(\n",
    "        fn_args.eval_files,\n",
    "        tf_transform_output,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_builder,\n",
    "        objective='val_sparse_categorical_accuracy',\n",
    "        max_trials=10,\n",
    "        directory=fn_args.working_dir,\n",
    "        project_name='tfx_tuner'\n",
    "    )\n",
    "\n",
    "    return TunerFnResult(\n",
    "        tuner=tuner,\n",
    "        fit_kwargs={\n",
    "            \"x\": train_dataset,\n",
    "            \"validation_data\": eval_dataset,\n",
    "            \"steps_per_epoch\": fn_args.train_steps,\n",
    "            \"validation_steps\": fn_args.eval_steps,\n",
    "            \"epochs\": 10,\n",
    "            \"callbacks\": [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc28a20",
   "metadata": {},
   "source": [
    "membuat trainer module file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee83b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modules/trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_MODULE_FILE}\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from transform import (\n",
    "    CATEGORICAL_FEATURES,\n",
    "    LABEL_KEY,\n",
    "    NUMERICAL_FEATURES,\n",
    "    transformed_name,\n",
    ")\n",
    "\n",
    "\n",
    "def get_model(show_summary=True):\n",
    "    \"\"\"Define Keras model.\"\"\"\n",
    "    input_features = []\n",
    "\n",
    "    for key, dim in CATEGORICAL_FEATURES.items():\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(dim + 1,), name=transformed_name(key))\n",
    "        )\n",
    "\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1,), name=transformed_name(feature))\n",
    "        )\n",
    "\n",
    "    concat = tf.keras.layers.concatenate(input_features)\n",
    "    deep = tf.keras.layers.Dense(256, activation=\"relu\")(concat)\n",
    "    deep = tf.keras.layers.Dense(64, activation=\"relu\")(deep)\n",
    "    deep = tf.keras.layers.Dense(16, activation=\"relu\")(deep)\n",
    "\n",
    "    num_classes = 4\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(deep)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def gzip_reader_fn(filenames):\n",
    "    \"\"\"Loads compressed data\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
    "\n",
    "\n",
    "def get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        feature_spec.pop(LABEL_KEY)\n",
    "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "\n",
    "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
    "    \"\"\"Generates features and labels for tuning/training.\n",
    "    Args:\n",
    "        file_pattern: input tfrecord file pattern.\n",
    "        tf_transform_output: A TFTransformOutput.\n",
    "        batch_size: representing the number of consecutive elements of\n",
    "        returned dataset to combine in a single batch\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features\n",
    "        is a dictionary of Tensors, and indices is a single Tensor of\n",
    "        label indices.\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=gzip_reader_fn,\n",
    "        label_key=transformed_name(LABEL_KEY),\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args):\n",
    "    \"\"\"Train the model based on given args.\n",
    "    Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "    \"\"\"\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, 64)\n",
    "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, 64)\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, update_freq=\"batch\"\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        epochs=10,\n",
    "    )\n",
    "\n",
    "    signatures = {\n",
    "        \"serving_default\": get_serve_tf_examples_fn(\n",
    "            model, tf_transform_output\n",
    "        ).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "        ),\n",
    "    }\n",
    "    model.save(fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures)\n",
    "\n",
    "    plot_model(\n",
    "        model, to_file=\"images/model_plot.png\", show_shapes=True, show_layer_names=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c677b24",
   "metadata": {},
   "source": [
    "Melakukan inisialisasi local pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0b2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_local_pipeline(components, pipeline_root: Text) -> pipeline.Pipeline:\n",
    "    logging.info(f\"Pipeline root set to: {pipeline_root}\")\n",
    "    beam_args = [\n",
    "        \"--direct_running_mode=multi_processing\"\n",
    "        # 0 auto-detect based on on the number of CPUs available\n",
    "        # during execution time.\n",
    "        \"----direct_num_workers=0\"\n",
    "    ]\n",
    "\n",
    "    return pipeline.Pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=pipeline_root,\n",
    "        components=components,\n",
    "        enable_cache=True,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
    "            metadata_path\n",
    "        ),\n",
    "        beam_pipeline_args=beam_args,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04ead9",
   "metadata": {},
   "source": [
    "Menjalankan pipeline menggunakan Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0a03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Choice', 'config': {'name': 'units_1', 'default': 128, 'conditions': [], 'values': [128, 256, 512], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'dropout_1', 'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'units_2', 'default': 64, 'conditions': [], 'values': [64, 128], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'dropout_2', 'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'units_3', 'default': 32, 'conditions': [], 'values': [32, 64], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'dropout_3', 'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}}], 'values': {'units_1': 512, 'dropout_1': 0.4, 'units_2': 128, 'dropout_2': 0.4, 'units_3': 64, 'dropout_3': 0.2, 'learning_rate': 0.001}}\n",
      "INFO:absl:Best Hyperparameters are written to output\\pilcotech-obesity-pipeline\\Tuner\\best_hyperparameters\\6\\best_hyperparameters.txt.\n",
      "INFO:absl:Tuner results are written to output\\pilcotech-obesity-pipeline\\Tuner\\tuner_results\\6\\tuner_results.json.\n",
      "INFO:absl:Running publisher for Tuner\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Generating ephemeral wheel package for 'd:\\\\tfx\\\\Submmison_Akhir\\\\modules\\\\trainer.py' (including modules: ['components', 'trainer', 'transform', 'tuner']).\n",
      "INFO:absl:User module package has hash fingerprint version c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85.\n",
      "INFO:absl:Executing: ['d:\\\\tfx\\\\Submmison_Akhir\\\\.venv\\\\Scripts\\\\python.exe', 'C:\\\\Users\\\\acer\\\\AppData\\\\Local\\\\Temp\\\\tmpnpxstq_8\\\\_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', 'C:\\\\Users\\\\acer\\\\AppData\\\\Local\\\\Temp\\\\tmpxfqakgs3', '--dist-dir', 'C:\\\\Users\\\\acer\\\\AppData\\\\Local\\\\Temp\\\\tmp6wpy9on2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 20s]\n",
      "val_sparse_categorical_accuracy: 1.0\n",
      "\n",
      "Best val_sparse_categorical_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 21m 47s\n",
      "Results summary\n",
      "Results in output\\pilcotech-obesity-pipeline\\.temp\\6\\tfx_tuner\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_sparse_categorical_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_1: 512\n",
      "dropout_1: 0.4\n",
      "units_2: 128\n",
      "dropout_2: 0.4\n",
      "units_3: 64\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "dropout_1: 0.3\n",
      "units_2: 128\n",
      "dropout_2: 0.3\n",
      "units_3: 32\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "dropout_1: 0.2\n",
      "units_2: 64\n",
      "dropout_2: 0.4\n",
      "units_3: 32\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "dropout_1: 0.2\n",
      "units_2: 128\n",
      "dropout_2: 0.4\n",
      "units_3: 32\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_1: 512\n",
      "dropout_1: 0.3\n",
      "units_2: 128\n",
      "dropout_2: 0.2\n",
      "units_3: 64\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "dropout_1: 0.4\n",
      "units_2: 64\n",
      "dropout_2: 0.4\n",
      "units_3: 64\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "dropout_1: 0.3\n",
      "units_2: 128\n",
      "dropout_2: 0.3\n",
      "units_3: 64\n",
      "dropout_3: 0.2\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9524062275886536\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units_1: 256\n",
      "dropout_1: 0.3\n",
      "units_2: 128\n",
      "dropout_2: 0.3\n",
      "units_3: 64\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9524062275886536\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_1: 512\n",
      "dropout_1: 0.4\n",
      "units_2: 128\n",
      "dropout_2: 0.2\n",
      "units_3: 64\n",
      "dropout_3: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.9524062275886536\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units_1: 256\n",
      "dropout_1: 0.2\n",
      "units_2: 128\n",
      "dropout_2: 0.4\n",
      "units_3: 32\n",
      "dropout_3: 0.3\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9523749947547913\n",
      "Running component: Trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully built user code wheel distribution at 'output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl'; target user module is 'trainer'.\n",
      "INFO:absl:Full user module path is 'trainer@output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl'\n",
      "INFO:absl:Running driver for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Trainer\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'train_args': '{\\n  \"num_steps\": 5000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'eval_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'module_file': None, 'run_fn': None, 'trainer_fn': None, 'custom_config': 'null', 'module_path': 'trainer@output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl'} 'run_fn'\n",
      "INFO:absl:Installing 'output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['d:\\\\tfx\\\\Submmison_Akhir\\\\.venv\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', '--target', 'C:\\\\Users\\\\acer\\\\AppData\\\\Local\\\\Temp\\\\tmpbyo0ll2j', 'output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl']\n",
      "INFO:absl:Successfully installed 'output\\\\pilcotech-obesity-pipeline\\\\_wheels\\\\tfx_user_code_Trainer-0.0+c1f279af4dd3aece4ce778c5bdcf0aab5122d7518f65a6baf825d1e516f1ec85-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature Age_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature BMI_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Gender_xf has a shape dim {\n",
      "  size: 3\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Height_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Label_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Weight_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Age_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature BMI_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Gender_xf has a shape dim {\n",
      "  size: 3\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Height_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Label_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Weight_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Gender_xf (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " Height_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Weight_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " BMI_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 7)            0           ['Gender_xf[0][0]',              \n",
      "                                                                  'Height_xf[0][0]',              \n",
      "                                                                  'Weight_xf[0][0]',              \n",
      "                                                                  'BMI_xf[0][0]',                 \n",
      "                                                                  'Age_xf[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          2048        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           16448       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           1040        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            68          ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,604\n",
      "Trainable params: 19,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 5.8012e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2057 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 2.8866e-07 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 2.1588e-08 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 5.7358e-09 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4857 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 6.2188e-08 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5882 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 1.4296e-08 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 5.8383e-09 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8819 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9993 - val_loss: 1.0941e-05 - val_sparse_categorical_accuracy: 1.0000\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "INFO:absl:Feature Age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature BMI has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Height has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Label has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Weight has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\tfx\\Submmison_Akhir\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\tfx\\Submmison_Akhir\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\pilcotech-obesity-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\pilcotech-obesity-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Training complete. Model written to output\\pilcotech-obesity-pipeline\\Trainer\\model\\7\\Format-Serving. ModelRun written to output\\pilcotech-obesity-pipeline\\Trainer\\model_run\\7\n",
      "INFO:absl:Running publisher for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running driver for Latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running component: Latest_blessed_model_resolver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Running publisher for Latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running driver for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Evaluator\n",
      "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Label_xf\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"Gender_xf\"\\n      ]\\n    }\\n  ]\\n}', 'feature_slicing_spec': None, 'fairness_indicator_thresholds': 'null', 'example_splits': 'null', 'module_file': None, 'module_path': None} 'custom_eval_shared_model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running component: Evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Label_xf\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"Gender_xf\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using output\\pilcotech-obesity-pipeline\\Trainer\\model\\7\\Format-Serving as  model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028964E07D00> and <keras.engine.input_layer.InputLayer object at 0x0000028961323CA0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028964E07D00> and <keras.engine.input_layer.InputLayer object at 0x0000028961323CA0>).\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"Label_xf\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"Gender_xf\"\\n      ]\\n    }\\n  ]\\n}', 'feature_slicing_spec': None, 'fairness_indicator_thresholds': 'null', 'example_splits': 'null', 'module_file': None, 'module_path': None} 'custom_extractors'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Label_xf\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"Gender_xf\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Label_xf\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"Gender_xf\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Label_xf\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"Gender_xf\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289617CCA00> and <keras.engine.input_layer.InputLayer object at 0x00000289612055B0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289617CCA00> and <keras.engine.input_layer.InputLayer object at 0x00000289612055B0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002896D40E0D0> and <keras.engine.input_layer.InputLayer object at 0x00000289617462B0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002896D40E0D0> and <keras.engine.input_layer.InputLayer object at 0x00000289617462B0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028961862730> and <keras.engine.input_layer.InputLayer object at 0x00000289619EF940>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028961862730> and <keras.engine.input_layer.InputLayer object at 0x00000289619EF940>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028970D87910> and <keras.engine.input_layer.InputLayer object at 0x0000028970C10280>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028970D87910> and <keras.engine.input_layer.InputLayer object at 0x0000028970C10280>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002896131EB80> and <keras.engine.input_layer.InputLayer object at 0x00000289611CDCD0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002896131EB80> and <keras.engine.input_layer.InputLayer object at 0x00000289611CDCD0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028970E1A6A0> and <keras.engine.input_layer.InputLayer object at 0x0000028970DFF4C0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000028970E1A6A0> and <keras.engine.input_layer.InputLayer object at 0x0000028970DFF4C0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289711E5DF0> and <keras.engine.input_layer.InputLayer object at 0x0000028971173460>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289711E5DF0> and <keras.engine.input_layer.InputLayer object at 0x0000028971173460>).\n",
      "INFO:absl:Evaluation complete. Results written to output\\pilcotech-obesity-pipeline\\Evaluator\\evaluation\\9.\n",
      "INFO:absl:Checking validation results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\tfx\\Submmison_Akhir\\.venv\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\tfx\\Submmison_Akhir\\.venv\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:absl:Blessing result True written to output\\pilcotech-obesity-pipeline\\Evaluator\\blessing\\9.\n",
      "INFO:absl:Running publisher for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running driver for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Pusher\n",
      "INFO:absl:Model version: 1751855789\n",
      "INFO:absl:Model written to serving path output\\serving_model\\1751855789.\n",
      "INFO:absl:Model pushed to output\\pilcotech-obesity-pipeline\\Pusher\\pushed_model\\10.\n",
      "INFO:absl:Running publisher for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running component: Pusher\n"
     ]
    }
   ],
   "source": [
    "from modules.components import init_components\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "\n",
    "components = init_components(\n",
    "    DATA_ROOT,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    tuner_module=TUNER_MODULE_FILE,\n",
    "    training_steps=5000,\n",
    "    eval_steps=1000,\n",
    "    serving_model_dir=serving_model_dir,\n",
    ")\n",
    "\n",
    "# Jalankan komponen satu per satu\n",
    "context = InteractiveContext(pipeline_root=pipeline_root)\n",
    "for c in components:\n",
    "        print(f\"Running component: {c.id}\")\n",
    "        context.run(c)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
